services:
  # 1. O Motor da IA (Ollama)
  ollama:
    image: ollama/ollama:latest
    container_name: devopsai_ollama
    ports:
      - "11434:11434"
    volumes:
      # Persiste os modelos (ex: llama3.2) para não baixar novamente
      - ollama_storage:/root/.ollama
      # Monta certificados do sistema (se disponíveis)
      - /etc/ssl/certs:/etc/ssl/certs:ro
    environment:
      # Configurações de proxy (se necessário)
      - HTTP_PROXY=${HTTP_PROXY:-}
      - HTTPS_PROXY=${HTTPS_PROXY:-}
      - NO_PROXY=${NO_PROXY:-localhost,127.0.0.1}
      # Para ignorar verificação SSL (use apenas se necessário)
      - SSL_SKIP_VERIFY=${SSL_SKIP_VERIFY:-false}
    restart: unless-stopped

  # 2. O Backend (FastAPI + ChromaDB)
  backend:
    build: ./backend
    container_name: devopsai_backend
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      # Persiste o banco de vetores (ChromaDB)
      # Mapeia o volume 'chroma_storage' para a pasta criada pelo script Python
      - chroma_storage:/app/chroma_db
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: on-failure

  # 3. O Frontend (Streamlit)
  frontend:
    build: ./frontend
    container_name: devopsai_frontend
    ports:
      - "8501:8501"
    environment:
      - BACKEND_URL=http://backend:8000
    depends_on:
      backend:
        condition: service_healthy
    restart: on-failure

# Definição dos Volumes Gerenciados pelo Docker
volumes:
  ollama_storage:
    name: devopsai_ollama_data
  chroma_storage:
    name: devopsai_chroma_data